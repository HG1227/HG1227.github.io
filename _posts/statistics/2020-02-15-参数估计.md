---
layout: post
title:  参数估计
date:   2020-02-15
categories: statistics
tags:  
---
* content
{:toc}


## 估计量

在[统计学](https://zh.wikipedia.org/wiki/统计学)中，**估计量**是基于观测数据计算一个已知量的估计值的法则

估计量用来估计未知总体的[参数](https://zh.wikipedia.org/wiki/参数)，它有时也被称为**估计子**；一次**估计**是指把这个函数应用在一组已知的数据集上，求函数的结果。对于给定的参数，可以有许多不同的估计量。我们通过一些选择标准从它们中选出较好的估计量，但是有时候很难说选择这一个估计量比另外一个好。

### 定义

假设存在一个固定的待估*参数* $$\theta $$。那么"估计量"是[样本空间](https://zh.wikipedia.org/wiki/样本空间)映射到*样本估计值*的一个函数。$$ \theta $$的一个估计量记为 $$ {\widehat {\theta }}$$ 。

易用随机变量的代数来阐述这个理论：如果用*X*来标记对应观测数据的[随机变量](https://zh.wikipedia.org/wiki/随机变量)，估计量（本身视为随机变量）的符号表示为该随机变量的函数，$$\widehat\theta (X)$$ 。对特定观测数据集（即对于$$X=x$$）而言，其估计值为一固定值$$ {\widehat {\theta }}(x)$$ 。通常使用简化标记  $${\widehat {\theta }}$$ 表示随机变量，但这容易造成误解。

误差

对于一个给定样本$$ x$$，估计量 $$\widehat {\theta }$$ 的"[误差](https://zh.wikipedia.org/wiki/误差)"定义为
$$
\begin{equation}e(x)=\hat{\theta}(x)-\theta\end{equation}
$$
其中 ${\displaystyle \theta }$ 是待估参数。注意误差 $e$ 不仅取决于估计量（估计公式或过程），还取决于样本。

### 均方误差

估计量 ${\displaystyle {\hat {\theta }}}$ 的均方误差被定义为误差的平方的期望值，即为：
$$
\begin{equation}M S E(\hat{\theta})=E\left[(\hat{\theta}(x)-\theta)^{2}\right]\end{equation}
$$
它用来显示估计值的集合与被估计单个参数的平均差异。

试想下面的类比：假设“参数”是靶子的靶心，“估计量”是向靶子射箭的过程，而每一支箭则是“估计值”（样本）。那么，高均方误差就意味着每一支箭离靶心的平均距离较大，低均方误差则意味着每一支箭离靶心的平均距离较小。箭支可能集聚，也可能不。比如说，即使所有箭支都射中了同一个点，同时却严重偏离了靶子，均方误差相对来说依然很大。然而要注意的是，如果均方误差相对较小，箭支则更有可能集聚（而不是离散）。

### 行为特性

判断一个估计量“好坏”，至少可以从以下三个方面来考虑：无偏性、有效性、一致性。

## 估计值

在数理统计中，一般用子样观测值求出的统计量来估计总体的一个未知参数，此统计量称为参数的**估计量**。子样一组观测值所对应估计量的值，称为参数的**估计值**。

估计值亦称[**估计量**](https://baike.baidu.com/item/估计量)的实现，简称[**估计**](https://baike.baidu.com/item/估计)，是指估计量的具体数值。在进行理论分析和一般性讨论时，未知参数θ的估计量  $$\theta=T\left(X_{1}, X_{2}, \ldots, X_{n}\right)$$ 作为随机样本的函数，是随机变量；在实际应用中，样本是一组统计数据 $$x_{1}, x_{2}, \ldots, x_{n}$$ (随机样本的实现——样本值)，而估计量 $\theta$ 相应地取一具体值 $$\theta=T\left(x_{1}, x_{2}, \ldots, x_{n}\right)$$ ，即为 $\theta$  的估计值。

## 点估计

**点估计（Point estimation）**

**点估计**也称**定值估计**，它是以[抽样](https://wiki.mbalib.com/wiki/抽样)得到的[样本指标](https://wiki.mbalib.com/wiki/样本指标)作为[总体指标](https://wiki.mbalib.com/wiki/总体指标)的估计量，并以样本指标的实际值直接作为总体未知参数的估计值的一种推断方法。

### 点估计的方法

点估计的方法有[矩估计法](https://wiki.mbalib.com/w/index.php?title=矩估计法&action=edit)、[顺序统计量法](https://wiki.mbalib.com/wiki/顺序统计量法)、[最大似然法](https://wiki.mbalib.com/wiki/最大似然法)、[最小二乘法](https://wiki.mbalib.com/wiki/最小二乘法)等。

矩估计法。

在[统计学](https://wiki.mbalib.com/wiki/统计学)中，矩是指以期望为基础而定义的数字特征，一般分为原点矩和中心矩。

设 $X$ 为[随机变量](https://wiki.mbalib.com/wiki/随机变量)，对任意正整数k，称 $$E\left(X^{k }\right)$$ 为随机变量 $X$ 的 k 阶原点矩，记为：
$$
m_k = E\left(X^{k }\right)
$$
当k＝1时，
$$
m_1 = E(X) = \mu
$$
可见一阶原点矩为随机变量X的数学期望。

把 $$C_{k }=E[X-E(X)]^{k}$$  称为以$E(X)$为中心的k阶中心矩。

显然，当k＝2时
$$
C_{2 }=E[X-E(X)]^{2}
$$
可见二阶中心矩为随机变量X的[方差](https://wiki.mbalib.com/wiki/方差)。

<center><img src="https://raw.githubusercontent.com/HG1227/image/master/img_tuchuang/20200601131841.png"/></center>
　矩估计法简便、直观，比较常用，但是矩估计法也有其局限性。首先，它要求总体的k阶原点矩存在，若不存在则无法估计；其次，矩估计法不能充分地利用估计时已掌握的有关总体分布形式的信息。

通常设 $θ$ 为总体X的待估计参数，一般用样本 $$X_{1}, X_{2}, \cdots, X_{n}$$  构成一个统计量 $$\hat{\theta}=\hat{\theta}\left(X_{1}, X_{2}, \Lambda, X_{n}\right)$$ 来估计 $θ$ 则称 $\hat{\theta}$ 为θ的**估计量**。对于样本的一组数值 $$x_{1}, x_{2}, \cdots, x_{n}$$ 称θ的**估计值**。于是点估计即是寻求一个作为待估计参数θ的估计量  $\hat{\theta}(x_{1}, x_{2}, \cdots, x_{n})$ 的问题。但是必须注意，对于样本的不同数值，估计值是不相同的。

## 极大似然估计

**最大似然估计**（英语：maximum likelihood estimation，缩写为MLE），也称**极大似然估计**

最大似然估计的目的就是：利用已知的样本结果，反推最有可能（最大概率）导致这样结果的参数值。

原理：极大似然估计是建立在极大似然原理的基础上的一个统计方法，是概率论在统计学中的应用。极大似然估计提供了一种给定观察数据来评估模型参数的方法，即：“模型已定，参数未知”。通过若干次试验，观察其结果，利用试验结果得到某个参数值能够使样本出现的概率为最大，则称为极大似然估计。

<center><img src="https://raw.githubusercontent.com/HG1227/image/master/img_tuchuang/20200601163935.png"/></center>
### 如果总体X为离散型

假设分布率为 $$P=p(x ; \theta)$$，x 是发生的样本，$θ$ 是代估计的参数，$$p(x ; \theta)$$表示估计参数为θθ时，发生x的的概率。

那么当我们的样本值为：$$x_{1}, x_{2}, \ldots, x_{n}$$ 时，
$$
\begin{equation}L(\theta)=L\left(x_{1}, x_{2}, \ldots, x_{n} ; \theta\right)=\prod_{i=1}^{n} p\left(x_{i} ; \theta\right)\end{equation}
$$
其中$L(θ)$ 成为样本的似然函数。

假设 
$$
\begin{equation}L\left(x_{1}, x_{2}, \ldots, x_{n} ; \hat{\theta}\right)=\max _{\theta \in \Theta} L\left(x_{1}, x_{2}, \ldots, x_{n} ; \theta\right)\end{equation}
$$
有 $\hat{\theta}$ 使得$ L(θ)$  的取值最大，那么  $\hat{\theta}$  就叫做参数 $\theta$ 的极大似然估计值。

### 如果总体X为连续型

基本和上面类似，只是概率密度为 $$f(x ; \theta)$$ ，替代p。
$$
\begin{equation}L(\theta)=\prod_{i=1}^{n} f\left(x_{i} ; \theta\right)\end{equation}
$$
解法

1. 构造似然函数 $L(θ)$ 
2. 取对数：$lnL(θ)$
3. 求导，计算极值
4. 解方程，得到 $θ$ 

## 估计量的评判标准

**1 无偏性** **2 有效性**  **3 一致性**

## 区间估计

用点估计 $$\hat{\theta}\left(X_{1}, X_{2}, \ldots, X_{n}\right)$$ 来估计总体的未知参数 $\theta$ 一旦我们获得了样本观察值  $$\left(x_{1}, x_{2}, \ldots, x_{n}\right)$$ 

将它代入   $$\hat{\theta}\left(X_{1}, X_{2}, \ldots, X_{n}\right)$$  即可得到 $θ$ 的一个估计值。这很直观，也很便于使用。但是，点估计值只提供了$ $ 的一个近似值，并没有反映这种近似的精确度。同时，由于 $θ$ 本身是未知的，我们也无从知道这种估计的误差大小。因此，我们希望估计出一个真实参数所在的范围，并希望知道这个范围以多大的概率包含参数真值，这就是参数的区间估计问题。

### 定义

设总体 $$X \sim F(x ; \theta)$$ ，$\theta$ 是待估计参数，若对给定的 $\alpha (0<\alpha <1)$ , 存在两个统计量 ：$$\underline{\theta}=\underline{\theta}\left(X_{1}, X_{2}, \cdots, X_{n}\right), \quad \bar{\theta}=\bar{\theta}\left(X_{1}, X_{2}, \cdots, X_{n}\right)$$ 使得 $$P\{\underline{\theta}<\theta<\overline{\boldsymbol{\theta}}\}=1-\alpha, \quad \boldsymbol{\theta} \in \Theta$$ 

则称随机区间 $$(\underline{\theta}, \bar{\theta})$$ 为 $\theta$ 的置信度为 $1-\alpha$ 的置信区间， $$\underline{\theta}, \bar{\theta}$$  分别成为置信下限和置信上限， $1-\alpha$ 成为置信度或置信水平。

区间估计的几点说明：

- 置信区间的长度  $$\bar{\theta}-\underline{\theta}$$  反映了**估计的精度**，  $$\bar{\theta}-\underline{\theta}$$  越小，估计精度越高。
- $\alpha$ 反映了估计的可信度。$\alpha$ 越小，$1-\alpha$ 越大，估计的可信度越高；但通常会导致   $$\bar{\theta}-\underline{\theta}$$   增大。从而导致估计的精度降低。
- $\alpha$ 给定后，置信区间的选取不唯一，通常选取 $$\bar{\theta}-\underline{\theta}$$   最小的区间。

值得注意的是，置信区间 $$\left(\hat{\theta}_{1}, \hat{\theta}_{2}\right)$$ 是一个随机区间，对于给定的样本 $$\left(X_{1}, X_{2}, \ldots, X_{n}\right)$$， 可能包含未知参数(θ^1,θ^2)(θ^1,θ^2)，也可能不包含 $$\left(\hat{\theta}_{1}, \hat{\theta}_{2}\right)$$ 。但在重复取样下，将得到许多不同的区间$$\hat{\theta}_{1}\left(x_{1}, x_{2}, \ldots, x_{n}\right), \hat{\theta}_{2}\left(x_{1}, x_{2}, \ldots, x_{n}\right)$$，根据贝努利大数定律，这些区间中大约有$100(1−\alpha)$ 的区间包含未知参数 $\theta$  。

### 置信区间的含义

以$\alpha=0.01$为例，此时置信度为99。假设反复抽取样本1000次，则得到1000个随机区间 $$\left(\hat{\theta}_{1}, \hat{\theta}_{2}\right)$$ ,在这1000个区间中，包含值的大约有990个，而不包含 $\theta$ 值的大约有10个。

### 区间估计的步骤

1.构造一个与 $\theta$ 有关的函数 $U$  (又称为枢轴变量)

(1) $U$ 不含其他参数，(2)已知 $U$  的分布

2对给定的 $\alpha (0<\alpha<1)$，求 $a,b$ 使得
$$
\begin{equation}P\{a \leq U \leq b\}=1-\alpha\end{equation}
$$


3 解不等式 $$a \leq U \leq b \Leftrightarrow T_{1} \leq \theta \leq T_{2}$$ ,得到区间$$[\hat{\theta}_{1}, \hat{\theta}_{2}]$$



例 设 $$X_{1}, X_{2}, \cdots, X_{n}$$  来自总体 $$X \sim N(\mu, 1)$$ 的样本， 求$\mu$ 的置信度为 $1-\alpha$ 的置信区间

解：

$\mu$ 的无偏估计为 $\bar{X}$ ,且
$$
\begin{equation}\bar{X} \sim N\left(\mu, \frac{1}{n}\right) \hookrightarrow \frac{\bar{X}-\mu}{1 / \sqrt{n}} \sim N(0,1)\end{equation}
$$


即 $$U =\frac{\bar{X}-\mu}{1 / \sqrt{n}} $$ 

由此得到 $$P\left\{-u_{1-a/2}<\frac{\bar{X}-\mu}{1 / \sqrt{n}}<u_{1-\alpha/2} \right\}=1-\alpha$$ 

即 $$P\left\{\bar{X}-\frac{1}{\sqrt{n}} u_{1-\alpha/2}<\mu<\bar{X}+\frac{1}{\sqrt{n}} u_{1-\alpha/2},\right\}=1-\alpha$$ 

所以 $\mu$ 的置信度为 $1-\alpha$ 的置信区间为：
$$
\begin{equation}\left(\bar{X}-\frac{1}{\sqrt{n}} u_{1-\alpha / 2}, \bar{X}+\frac{1}{\sqrt{n}} u_{1-\alpha / 2}\right)\end{equation}
$$


### 正态总体参数的区间估计

一 一个总体 $$N\left(\mu, \sigma^{2}\right)$$ 的情形

1、方差 $$\sigma^{2}$$ 未知，$\mu$ 的置信区间

设  $$X_{1}, X_{2}, \cdots, X_{n}$$  是总体 $$X \sim N\left(\mu, \sigma^{2}\right)$$ 的样本， $\sigma^{2}$ 未知，求 $\mu$ 的置信度为 $1-\alpha$ 的置信区间

因为 $\mu$ 的 MLE 是 $\bar{X}$ 选取枢轴变量
$$
\begin{equation}\frac{\bar{X}-\mu}{\sigma / \sqrt{n}}\end{equation}
$$


因为枢轴变量的要求是：样本和待估参数的函数，而且它的分布要已知，且不能含有任何未知参数，上面的式子中 $\sigma$ 是未知的，和枢轴变量的要求不吻合，解决方法，**用样本的标准差代替未知的整体的标准差**，即
$$
\begin{equation}\frac{\bar{X}-\mu}{S / \sqrt{n}}\end{equation}
$$


$S$ 样本标准差

找出上面的函数的已知分布，满足 自由度为 $n-1$ 的 $t$ 分布，即
$$
\begin{equation}\frac{\bar{X}-\mu}{S / \sqrt{n}}\sim t(n-1)\end{equation}
$$


既有：
$$
\begin{equation}P\left(-t_{1-\frac{\alpha}{2}}(n-1)<\frac{\bar{X}-\mu}{S / \sqrt{n}}<t_{1-\frac{\alpha}{2}}(n-1)\right\}=1-\alpha\end{equation}
$$


解：
$$
\begin{equation}-t_{1-\frac{\alpha}{2}}(n-1)<\frac{\boldsymbol{X}-\mu}{\boldsymbol{S} / \sqrt{\boldsymbol{n}}}<t_{1- \frac{\alpha}{2}}(n-1)\end{equation}
$$


得 $\mu$ 的置信度为 $1-\alpha$ 的置信区间为
$$
\begin{equation}\left(\bar{X}-t_{1- \frac{\alpha}{2}}(n-1) \frac{S}{\sqrt{n}},\bar{X}+t_{1- \frac{\alpha}{2}}(n-1) \frac{S}{\sqrt{n}}\right)\end{equation}
$$
2、$\mu$ 未知，方差 $\sigma^{2}$ 的置信区间

设  $$X_{1}, X_{2}, \cdots, X_{n}$$  是总体 $$X \sim N\left(\mu, \sigma^{2}\right)$$ 的样本， $\mu$ 未知，求 $\sigma^{2}$ 的置信度为 $1-\alpha$ 的置信区间

  $\sigma^{2}$ 的MLE 是 $S^2$ (修正后的样本方差)，选取枢轴变量
$$
\begin{equation}\frac{n \tilde{S}^{2}}{\sigma^{2}}=\frac{(n-1) S^{2}}{\sigma^{2}}\end{equation}
$$
（上面的式子由 样本方差和修正后的样本方差关系转换得到的）

此时的分布：服从自由度为$n-1$ 的 卡方分布，即
$$
\begin{equation}\frac{(n-1) S^{2}}{\sigma^{2}}-\chi^{2}(n-1)\end{equation}
$$

<center><img src="https://raw.githubusercontent.com/HG1227/image/master/img_tuchuang/20200601154644.png"/></center>


既有 
$$
\begin{equation}P\left\{\chi_{\frac{\sigma}{2}}^{2}(n-1)<\frac{(n-1) S^{2}}{\sigma^{2}}<\chi_{1- \frac{\alpha}{2}}^{2}(n-1)\right\}=1-\alpha\end{equation}
$$

$$
\begin{equation}\chi_{\frac{\alpha}{2}}^{2}(n-1)<\frac{(n-1) S^{2}}{\sigma^{2}}<\chi_{1-\frac{\alpha}{2}}^{2}(n-1)\end{equation}
$$


得到 $\sigma^2$ 的置信度为 $1-\alpha$ 的置信区间为 
$$
\begin{equation}\left(\frac{(n-1) S^{2}}{X_{1- \frac{\alpha}{2}}^{2}(n-1)}, \frac{(n-1) S^{2}}{X_{\frac{\alpha}{2}}^{2}(n-1)}\right)\end{equation}
$$




### 一个总体参数的区间估计

### 总体均值的区间估计

### 正态总体、方差已知，或非正态总体、大样本

<center><img src="https://raw.githubusercontent.com/HG1227/image/master/img_tuchuang/20200601173735.png"/></center>
<center><img src="https://raw.githubusercontent.com/HG1227/image/master/img_tuchuang/20200601173813.png"/></center>
###  正态总体、方差未知、小样本

<center><img src="https://raw.githubusercontent.com/HG1227/image/master/img_tuchuang/20200601173902.png"/></center>


### 1.3 总结

<center><img src="https://raw.githubusercontent.com/HG1227/image/master/img_tuchuang/20200601174047.png"/></center>


## 二、总体比例的区间估计

<center><img src="https://raw.githubusercontent.com/HG1227/image/master/img_tuchuang/20200601174256.png"/></center>
## 三、正态总体方差分布的区间估计

<center><img src="https://raw.githubusercontent.com/HG1227/image/master/img_tuchuang/20200601174420.png"/></center>
## 总结

<center><img src="https://raw.githubusercontent.com/HG1227/image/master/img_tuchuang/20200601174705.png"/></center>




## 两个总体参数的区间估计

### 1.1 独立样本

#### (1) 大样本

<center><img src="https://raw.githubusercontent.com/HG1227/image/master/img_tuchuang/20200601190408.png"/></center>
<center><img src="https://raw.githubusercontent.com/HG1227/image/master/img_tuchuang/20200601190444.png"/></center>
#### (2) 小样本

<center><img src="https://raw.githubusercontent.com/HG1227/image/master/img_tuchuang/20200601190529.png"/></center>
### 1.2 匹配样本

<center><img src="https://raw.githubusercontent.com/HG1227/image/master/img_tuchuang/20200601192214.png"/></center>
<center><img src="https://raw.githubusercontent.com/HG1227/image/master/img_tuchuang/20200601192244.png"/></center>


## 二、两个总体比例之差的区间估计

<center><img src="https://raw.githubusercontent.com/HG1227/image/master/img_tuchuang/20200601192423.png"/></center>


## 三、两个总体方差比的区间估计

<center><img src="https://raw.githubusercontent.com/HG1227/image/master/img_tuchuang/20200601192533.png"/></center>
总结 

<center><img src="https://raw.githubusercontent.com/HG1227/image/master/img_tuchuang/20200601192615.png"/></center>


<center><img src="https://raw.githubusercontent.com/HG1227/image/master/img_tuchuang/20200601193436.png"/></center>
<center><img src="https://raw.githubusercontent.com/HG1227/image/master/img_tuchuang/20200601193511.png"/></center>




## 二、估计总体均值时样本量的确定

<center><img src="https://raw.githubusercontent.com/HG1227/image/master/img_tuchuang/20200601193816.png"/></center>
## 三、估计总体比例时样本量的确定

<center><img src="https://raw.githubusercontent.com/HG1227/image/master/img_tuchuang/20200601193906.png"/></center>








参考 

- <a href="https://wiki.mbalib.com/wiki/点估计" target="_blank">点估计</a>
- <a href="https://zh.wikipedia.org/wiki/估计量" target="_blank">估计量</a>
- <a href="https://blog.csdn.net/liangzuojiayi/article/details/78043658" target="_blank">统计学简介之八——一个总体参数的区间估计</a>
- <a href="https://blog.csdn.net/liangzuojiayi/category_7164089.html" target="_blank">统计学</a> 
- <a href="" target="_blank"></a>
- <a href="" target="_blank"></a>
- <a href="" target="_blank"></a>
- <a href="https://www.cnblogs.com/xing901022/p/8418894.html" target="_blank">极大似然估计的理解与应用</a>
- <a href="https://wenku.baidu.com/view/0d9af6aa172ded630b1cb69a.html" target="_blank">极大似然估计的原理和方法1</a>
- <a href="https://zh.wikipedia.org/wiki/最大似然估计" target="_blank">最大似然估计</a>