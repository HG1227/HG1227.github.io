---
layout: post
title:  机器学习中的矩阵向量求导(二) 矩阵向量求导之定义法
date:   2019-12-25
categories: math 
tags: Matrix
---
* content
{:toc}
标量对向量求导，标量对矩阵求导, 以及向量对向量求导这三种场景的基本求解思路。

标量对向量或矩阵求导这两种情况，以分母布局为默认布局。向量对向量求导，以分子布局为默认布局。



# **1. 用定义法求解标量对向量求导**

标量对向量求导，严格来说是实值函数对向量的求导。即定义实值函数 $f: R^{n} \to R$  ,自变量 $\mathbf{x}$ 是n维向量，而输出 $y$ 是标量。对于一个给定的实值函数，如何求解 $\frac{\partial y}{\partial \mathbf{x}}$  呢？

 

首先我们想到的是基于矩阵求导的定义来做，由于所谓标量对向量的求导，其实就是标量对向量里的每个分量分别求导，最后把求导的结果排列在一起，按一个向量表示而已。那么我们可以将实值函数对向量的每一个分量来求导，最后找到规律，得到求导的结果向量。



首先我们来看一个简单的例子：$y=\mathbf{a}^T\mathbf{x}$  ,求解 $\frac{\partial \mathbf{a}^T\mathbf{x}}{\partial \mathbf{x}}$ 

根据定义，我们先对 $\mathbf{x}$ 的第 $i$ 个分量进行求导，这是一个标量对标量的求导，如下：


$$
\begin{equation}
\frac{\partial \mathbf{a}^{T} \mathbf{x}}{\partial x_{i}}=\frac{\partial \sum_{j=1}^{n} a_{j} x_{j}}{\partial x_{i}}=\frac{\partial a_{i} x_{i}}{\partial x_{i}}=a_{i}
\end{equation}
$$


可见，对向量的第 $i$  个分量的求导结果就等于向量 $\mathbf{a}$ 的第i个分量。由于我们是分母布局，最后所有求导结果的分量组成的是一个n维向量。那么其实就是向量 $\mathbf{a}$ 。也就是说：


$$
\frac{\partial \mathbf{a}^T\mathbf{x}}{\partial \mathbf{x}} = \mathbf{a}
$$


同样的思路，我们也可以直接得到：


$$
\frac{\partial \mathbf{x}^T\mathbf{a}}{\partial \mathbf{x}} = \mathbf{a}
$$


再来看一个复杂一点点的例子：$y=\mathbf{x}^T\mathbf{A}\mathbf{x}$  ,求解 $\frac{\partial \mathbf{x}^T\mathbf{A}\mathbf{x}}{\partial \mathbf{x}}$ 



我们对 $\mathbf{x}$ 的第k个分量进行求导如下：


$$
\begin{equation}
\frac{\partial \mathbf{x}^{T} \mathbf{A} \mathbf{x}}{\partial x_{k}}=\frac{\partial \sum_{i=1}^{n} \sum_{j=1}^{n} x_{i} A_{i j} x_{j}}{\partial x_{k}}=\sum_{i=1}^{n} A_{i k} x_{i}+\sum_{j=1}^{n} A_{k j} x_{j}
\end{equation}
$$


这个第 k 个分量的求导结果稍微复杂些了，仔细观察一下，第一部分是矩阵 $\mathbf{A}$ 的第 k 列转置后和 $x$ 相乘得到，第二部分是矩阵 $\mathbf{A}$ 的第 k 行和 $x$ 相乘得到，排列好就是:


$$
\begin{equation}
\frac{\partial \mathbf{x}^{T} \mathbf{A} \mathbf{x}}{\partial \mathbf{x}}=\mathbf{A}^{T} \mathbf{x}+\mathbf{A} \mathbf{x}
\end{equation}
$$


从上面可以看出，定义法求导对于简单的实值函数是很容易的，但是复杂的实值函数就算求出了任意一个分量的导数，要排列出最终的求导结果还挺麻烦的，因此我们需要找到其他的简便一些的方法来整体求导，而不是每次都先去针对任意一个分量，再进行排列。



# **2. 标量对向量求导的一些基本法则**

在我们寻找一些简单的方法前，我们简单看下标量对向量求导的一些基本法则，这些法则和标量对标量求导的过程类似

- 常量对向量的求导结果为0。

- 线性法则：如果 $f,g$  都是实值函数，$c_1,c_2$  为常数，则：

  要注意的是如果不是实值函数，则不能这么使用乘法法则。
  

$$
\begin{equation}
   \frac{\partial\left(c_{1} f(\mathbf{x})+c_{2} g(\mathbf{x})\right.}{\partial \mathbf{x}}=c_{1} \frac{\partial f(\mathbf{x})}{\partial \mathbf{x}}+c_{2} \frac{\partial g(\mathbf{x})}{\partial \mathbf{x}}
   \end{equation}
$$

- 乘法法则：如果  $f,g$  都是实值函数，则：
  

$$
\begin{equation}
   \frac{\partial f(\mathbf{x}) g(\mathbf{x})}{\partial \mathbf{x}}=f(\mathbf{x}) \frac{\partial g(\mathbf{x})}{\partial \mathbf{x}}+\frac{\partial f(\mathbf{x})}{\partial \mathbf{x}} g(\mathbf{x})
   \end{equation}
$$

- 除法法则：如果  $f,g$  都是实值函数，且  $g(\mathbf{x}) \neq 0$  ，则：
  


$$
\begin{equation}
   \frac{\partial f(\mathbf{x}) / g(\mathbf{x})}{\partial \mathbf{x}}=\frac{1}{g^{2}(\mathbf{x})}\left(g(\mathbf{x}) \frac{\partial f(\mathbf{x})}{\partial \mathbf{x}}-f(\mathbf{x}) \frac{\partial g(\mathbf{x})}{\partial \mathbf{x}}\right)
   \end{equation}
$$



# **3. 用定义法求解标量对矩阵求导**

现在我们来看看定义法如何解决标量对矩阵的求导问题。其实思路和第一节的标量对向量的求导是类似的,只是最后的结果是一个和自变量同型的矩阵。



我们还是以一个例子来说明。$y=\mathbf{a}^T\mathbf{X}\mathbf{b}$  , 求解 $\frac{\partial \mathbf{a}^T\mathbf{X}\mathbf{b}}{\partial \mathbf{X}}$  

其中, $\mathbf{a}$ 是 m 维向量, $\mathbf{b}$ 是n维向量, $\mathbf{X}$ 是 $m \times n$ 的矩阵。

我们对矩阵 $\mathbf{X}$ 的任意一个位置的 $X_{ij}$  求导，如下：


$$
\begin{equation}
\frac{\partial \mathbf{a}^{T} \mathbf{X} \mathbf{b}}{\partial X_{i j}}=\frac{\partial \sum_{p=1}^{m} \sum_{q=1}^{n} a_{p} A_{p q} b_{q}}{\partial X_{i j}}=\frac{\partial a_{i} A_{i j} b_{j}}{\partial X_{i j}}=a_{i} b_{j}
\end{equation}
$$


即求导结果在 $(i.j)$  位置的求导结果是 $\mathbf{a}$  向量第i个分量和 $\mathbf{b}$ 第j个分量的乘积，将所有的位置的求导结果排列成一个 $m \times n$  的矩阵，即为 $ab^T$  ,这样最后的求导结果为：


$$
\frac{\partial \mathbf{a}^T\mathbf{X}\mathbf{b}}{\partial \mathbf{X}} = ab^T
$$


# **4.用定义法求解向量对向量求导**

先来一个简单的例子 : $\mathbf{y} = \mathbf{A} \mathbf{x}$  ,其中 $\mathbf{A}$  为 $n \times m$  的矩阵，$\mathbf{x}, \mathbf{y}$ 分别为 $m,n$ 维向量。需要求导 $\frac{\partial \mathbf{A}\mathbf{x}}{\partial \mathbf{x}}$ ,根据定义，结果应该是一个 $n \times m$ 的矩阵



先求矩阵的第i行和向量的内积对向量的第j分量求导，用定义法求解过程如下：


$$
\begin{equation}
\frac{\partial \mathbf{A}_{\mathbf{i}} \mathbf{x}}{\partial \mathbf{x}_{\mathbf{j}}}=\frac{\partial A_{i j} x_{j}}{\partial \mathbf{x}_{\mathbf{j}}}=A_{i j}
\end{equation}
$$


可见矩阵 $\mathbf{A}$ 的第i行和向量的内积对向量的第j分量求导的结果就是矩阵  $\mathbf{A}$ 的 $(i,j)$ 位置的值。排列起来就是一个矩阵了，由于我们分子布局，所以排列出的结果是   $\mathbf{A}$  , 而不是 $\mathbf{A}^T$ 。

