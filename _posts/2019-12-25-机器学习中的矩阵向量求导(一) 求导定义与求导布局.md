---
layout: post
title:  机器学习中的矩阵向量求导(一) 求导定义与求导布局
date:   2019-12-25
categories: math 
tags: Matrix
---
* content
{:toc}
机器学习中，矩阵向量求导的方法 。







# **1. 矩阵向量求导引入**

在高等数学里面，我们已经学过了标量对标量的求导，比如标量 $y$ 对标量 $x$ 的求导，可以表示为 $\frac{\partial y}{\partial x}$  .<br>

有些时候，我们会有一组标量 $y_i,i=1,2,...,m$  来对一个标量 $x$ 的求导,那么我们会得到一组标量求导的结果：


$$
\frac{\partial y_i}{\partial x}, i=1,2.,,,m
$$


如果我们把这组标量写成向量的形式，即得到维度为 m 的一个向量 $\mathbf{y}$ 对一个标量 $x$ 的求导，那么结果也是一个 m 维的向量：$\frac{\partial \mathbf{y}}{\partial x}$  <br>

所谓向量对标量的求导，其实就是向量里的每个分量分别对标量求导，最后把求导的结果排列在一起，按一个向量表示而已。类似的结论也存在于标量对向量的求导，向量对向量的求导，向量对矩阵的求导，矩阵对向量的求导，以及矩阵对矩阵的求导等。

总而言之，所谓的向量矩阵求导本质上就是多元函数求导，仅仅是把把函数的自变量，因变量以及标量求导的结果排列成了向量矩阵的形式，方便表达与计算，更加简洁而已。













